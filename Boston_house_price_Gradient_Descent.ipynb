{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Linear regression with Gradient Descent\n",
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset is included in sklearn\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['feature_names', 'DESCR', 'target', 'data'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# boston is a dictionary, showing the keys\n",
    "boston.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "alpha = 0.01 # learning rate\n",
    "num_epoch = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = boston.data\n",
    "y = boston.target\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = x / x.max(axis=0)  #Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = len(y)   # number of examples\n",
    "y = y.reshape(m,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.00000000e+00,   7.10302306e-05,   1.80000000e-01,\n",
       "          8.32732516e-02,   0.00000000e+00,   6.17680827e-01,\n",
       "          7.48861048e-01,   6.52000000e-01,   3.37277863e-01,\n",
       "          4.16666667e-02,   4.16315049e-01,   6.95454545e-01,\n",
       "          1.00000000e+00,   1.31156176e-01]])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build design matrix, which is x plus a '1' column in the first position\n",
    "x1 = np.insert(x,0,1,axis=1)  # insert a column of '1's into the first position of x\n",
    "x1[:1, :]  # first row "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.matrix(np.zeros((14,1)))  # initialize theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_descent(x1,y,theta,iter_num,alpha):\n",
    "    m = len(y)\n",
    "    costs=[]\n",
    "    for i in range(iter_num):\n",
    "\n",
    "        theta += x1.T*(y - x1*theta)*alpha/m\n",
    "        cost = 1/2/m * (x1*theta-y).T*(x1*theta-y)\n",
    "        if (i%10000)==0: \n",
    "            costs.append(cost)\n",
    "            print('iteration = %i, cost = %.8f' %(i,cost)) \n",
    "    return theta, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration = 0, cost = 273.24795670\n",
      "iteration = 10000, cost = 12.88252739\n",
      "iteration = 20000, cost = 11.83186548\n",
      "iteration = 30000, cost = 11.46491596\n",
      "iteration = 40000, cost = 11.27928278\n",
      "iteration = 50000, cost = 11.17493546\n",
      "iteration = 60000, cost = 11.11161597\n",
      "iteration = 70000, cost = 11.07050821\n",
      "iteration = 80000, cost = 11.04220572\n",
      "iteration = 90000, cost = 11.02176694\n",
      "iteration = 100000, cost = 11.00646587\n",
      "iteration = 110000, cost = 10.99471496\n",
      "iteration = 120000, cost = 10.98553331\n",
      "iteration = 130000, cost = 10.97827746\n",
      "iteration = 140000, cost = 10.97250163\n",
      "iteration = 150000, cost = 10.96788269\n",
      "iteration = 160000, cost = 10.96417818\n",
      "iteration = 170000, cost = 10.96120168\n",
      "iteration = 180000, cost = 10.95880741\n",
      "iteration = 190000, cost = 10.95688011\n",
      "iteration = 200000, cost = 10.95532803\n",
      "iteration = 210000, cost = 10.95407777\n",
      "iteration = 220000, cost = 10.95307046\n",
      "iteration = 230000, cost = 10.95225882\n",
      "iteration = 240000, cost = 10.95160479\n",
      "iteration = 250000, cost = 10.95107774\n",
      "iteration = 260000, cost = 10.95065301\n",
      "iteration = 270000, cost = 10.95031072\n",
      "iteration = 280000, cost = 10.95003488\n",
      "iteration = 290000, cost = 10.94981258\n",
      "iteration = 300000, cost = 10.94963343\n",
      "iteration = 310000, cost = 10.94948906\n",
      "iteration = 320000, cost = 10.94937270\n",
      "iteration = 330000, cost = 10.94927894\n",
      "iteration = 340000, cost = 10.94920337\n",
      "iteration = 350000, cost = 10.94914247\n",
      "iteration = 360000, cost = 10.94909339\n",
      "iteration = 370000, cost = 10.94905383\n",
      "iteration = 380000, cost = 10.94902196\n",
      "iteration = 390000, cost = 10.94899627\n",
      "iteration = 400000, cost = 10.94897557\n",
      "iteration = 410000, cost = 10.94895888\n",
      "iteration = 420000, cost = 10.94894544\n",
      "iteration = 430000, cost = 10.94893460\n",
      "iteration = 440000, cost = 10.94892587\n",
      "iteration = 450000, cost = 10.94891883\n",
      "iteration = 460000, cost = 10.94891316\n",
      "iteration = 470000, cost = 10.94890859\n",
      "iteration = 480000, cost = 10.94890490\n",
      "iteration = 490000, cost = 10.94890193\n",
      "iteration = 500000, cost = 10.94889954\n",
      "iteration = 510000, cost = 10.94889761\n",
      "iteration = 520000, cost = 10.94889606\n",
      "iteration = 530000, cost = 10.94889481\n",
      "iteration = 540000, cost = 10.94889380\n",
      "iteration = 550000, cost = 10.94889299\n",
      "iteration = 560000, cost = 10.94889233\n",
      "iteration = 570000, cost = 10.94889180\n",
      "iteration = 580000, cost = 10.94889138\n",
      "iteration = 590000, cost = 10.94889103\n",
      "iteration = 600000, cost = 10.94889076\n",
      "iteration = 610000, cost = 10.94889053\n",
      "iteration = 620000, cost = 10.94889035\n",
      "iteration = 630000, cost = 10.94889021\n",
      "iteration = 640000, cost = 10.94889009\n",
      "iteration = 650000, cost = 10.94889000\n",
      "iteration = 660000, cost = 10.94888992\n",
      "iteration = 670000, cost = 10.94888986\n",
      "iteration = 680000, cost = 10.94888981\n",
      "iteration = 690000, cost = 10.94888977\n",
      "iteration = 700000, cost = 10.94888974\n",
      "iteration = 710000, cost = 10.94888972\n",
      "iteration = 720000, cost = 10.94888970\n",
      "iteration = 730000, cost = 10.94888968\n",
      "iteration = 740000, cost = 10.94888966\n",
      "iteration = 750000, cost = 10.94888965\n",
      "iteration = 760000, cost = 10.94888965\n",
      "iteration = 770000, cost = 10.94888964\n",
      "iteration = 780000, cost = 10.94888963\n",
      "iteration = 790000, cost = 10.94888963\n",
      "iteration = 800000, cost = 10.94888962\n",
      "iteration = 810000, cost = 10.94888962\n",
      "iteration = 820000, cost = 10.94888962\n",
      "iteration = 830000, cost = 10.94888962\n",
      "iteration = 840000, cost = 10.94888962\n",
      "iteration = 850000, cost = 10.94888961\n",
      "iteration = 860000, cost = 10.94888961\n",
      "iteration = 870000, cost = 10.94888961\n",
      "iteration = 880000, cost = 10.94888961\n",
      "iteration = 890000, cost = 10.94888961\n",
      "iteration = 900000, cost = 10.94888961\n",
      "iteration = 910000, cost = 10.94888961\n",
      "iteration = 920000, cost = 10.94888961\n",
      "iteration = 930000, cost = 10.94888961\n",
      "iteration = 940000, cost = 10.94888961\n",
      "iteration = 950000, cost = 10.94888961\n",
      "iteration = 960000, cost = 10.94888961\n",
      "iteration = 970000, cost = 10.94888961\n",
      "iteration = 980000, cost = 10.94888961\n",
      "iteration = 990000, cost = 10.94888961\n"
     ]
    }
   ],
   "source": [
    "new_theta,costs = grad_descent(x1, y, theta, num_epoch, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
